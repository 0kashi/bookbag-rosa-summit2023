== Scaling

Scaling can refer to a few things.

. Manually scaling pods
. Pod autoscaling (Horizontal Pod Autoscaler)
. Node autoscaling

We will explore all three.

=== Pod scaling

OpenShift allows one to scale up/down the number of pods for each part of an application as needed.
This can be accomplished via changing our _replicaset/deployment_ definition (declarative), by the command line (imperative), or via the web console (imperative).
In our _deployment_ definition (part of our `ostoy-frontend-deployment.yaml`) we stated that we only want one pod for our microservice to start with.
This means that the Kubernetes Replication Controller will always strive to keep one pod alive.
We can also define pod autoscaling using the https://docs.openshift.com/container-platform/latest/nodes/pods/nodes-pods-autoscaling.html[Horizontal Pod Autoscaler](HPA) based on load to expand past what we defined if needed which we will do in a later section of this lab.

In the OSToy app click on "Networking" in the left menu to access this portion of the workshop.

If we look at the tile on the left ("Intra-cluster Communication") we should see one box randomly changing colors.
This box displays the randomly generated color sent to the frontend by our microservice along with the pod name that sent it.
Since we see only one box that means there is only one microservice pod.
We will now scale up our microservice pods and will see the number of boxes change.

image::images/12-networking.png[HPA Menu]

==== Confirm number of pods running

. To confirm that we only have one pod running for our microservice, run the following command, or use the web console.
+
[source,sh,role=execute]
----
oc get pods -n ostoy-${GUID}
----
+
.Sample Output
[source,text,options=nowrap]
----
NAME                                 READY   STATUS    RESTARTS      AGE
ostoy-frontend-84cbd867db-f2ggw      1/1     Running   1 (14m ago)   15m
ostoy-microservice-54789d5d9-rwj9s   1/1     Running   0             16m
----

==== Scale pods via Deployment definition

. Let's change our microservice definition yaml to reflect that we want 3 pods instead of the one we see.
+
[source,sh,role=execute]
----
oc scale deployment ostoy-microservice --replicas=3 -n ostoy-${GUID}
----
+
.Sample Output
[source,text,options=nowrap]
----
deployment.apps/ostoy-microservice scaled
----

. Confirm that there are now 3 pods via the CLI (`oc get pods`) or the web console (_Workloads > Deployments > ostoy-microservice_).
. See this visually by visiting the OSToy app > Networking in the left menu and counting how many boxes there are now.
It should be three.

image::images/8-ostoy-colorspods.png[UI Scale]

==== Scale down via CLI

Now we will scale the pods down using the command line.

. Execute the following command from the CLI:
+
[source,sh,role=execute]
----
oc scale deployment ostoy-microservice --replicas=2 -n ostoy-${GUID}
----
+
.Sample Output
[source,text,options=nowrap]
----
deployment.apps/ostoy-microservice scaled
----
   
. Confirm that there are indeed 2 pods, via the CLI or the web console.
+
[source,sh,role=execute]
----
oc get pods -n ostoy-${GUID}
----
+
.Sample Output
[source,text,options=nowrap]
----
NAME                                 READY   STATUS        RESTARTS      AGE
ostoy-frontend-84cbd867db-f2ggw      1/1     Running       1 (17m ago)   18m
ostoy-microservice-54789d5d9-mjmz4   1/1     Terminating   0             75s
ostoy-microservice-54789d5d9-rwj9s   1/1     Running       0             19m
ostoy-microservice-54789d5d9-wb5kj   1/1     Running       0             75s
----
+
[NOTE]
====
If you check quickly (like in the example above) you will see one of the pods in `Terminating` state. Re-run the command until it disappears.
====

.  See this visually by visiting the OSToy app and counting how many boxes there are now. It should be two.

==== Scale down via web console

Lastly, let's use the web console to scale back down to one pod.

* In the project you created for this app (ex: "ostoy") in the left menu click _Workloads > Deployments > ostoy-microservice_.
On the left you will see a blue circle with the number 2 in the middle.
* Click on the down arrow to the right of that to scale the number of pods down to 1.
+
image::images/8-ostoy-uiscale1.png[UI Scale]

* See this visually by visiting the OSToy app and counting how many boxes there are now.
It should be one.
* You can also confirm this via the CLI or the web console.

=== Pod Autoscaling

In this section we will explore how the https://docs.openshift.com/container-platform/latest/nodes/pods/nodes-pods-autoscaling.html[Horizontal Pod Autoscaler] (HPA) can be used and works within Kubernetes/OpenShift.
See here for link:/rosa/8-autoscaling[cluster autoscaling] in ROSA.

As defined in the documentation:

____
[...] you can use a horizontal pod autoscaler (HPA) to specify how OpenShift Container Platform should automatically increase or decrease the scale of a replication controller or deployment configuration, based on metrics collected from the pods that belong to that replication controller or deployment configuration.
____

In more simple words, "if there is a lot of work, make more pods".

We will create an HPA and then use OSToy to generate CPU intensive workloads.
We will then observe how the HPA will scale up the number of pods in order to handle the increased workloads.

Click on the "Auto Scaling" in the left menu.

image::images/12-hpa-menu.png[HPA Menu]

==== 1. Create the Horizontal Pod Autoscaler

Run the following command to create the autoscaler.
This will create an HPA that maintains between 1 and 10 replicas of the Pods controlled by the _ostoy-microservice_ Deployment created.
Roughly speaking, the HPA will increase and decrease the number of replicas (via the deployment) to maintain an average CPU utilization across all pods of 80% (since each pod requests 50 millicores, this means average CPU usage of 40 millicores).

[source,sh,role=execute]
----
oc autoscale deployment/ostoy-microservice --cpu-percent=80 --min=1 --max=10 -n ostoy-${GUID}
----

.Sample Output
[source,text,options=nowrap]
----
horizontalpodautoscaler.autoscaling/ostoy-microservice autoscaled
----

==== View the current number of pods

As was in the above section you will see the total number of pods available for the microservice by counting the number of colored boxes.
In this case we have only one.
This can be verified through the web console or from the CLI.

You can use the following command to see the running microservice pods only:

[source,sh,role=execute]
----
oc get pods --field-selector=status.phase=Running -n ostoy-${GUID} -lapp=ostoy-microservice
----

.Sample Output
[source,text,options=nowrap]
----
NAME                                 READY   STATUS    RESTARTS   AGE
ostoy-microservice-54789d5d9-rwj9s   1/1     Running   0          21m
ostoy-microservice-54789d5d9-wb5kj   1/1     Running   0          3m38s
----
or visually in our application:

image::images/12-hpa-mainpage.png[HPA Main]

==== Increase the load

Now that we know that we only have one pod let's increase the workload that the pod needs to perform.
Click the link in the center of the card that says "increase the load".

[WARNING]
====
*Please click only _ONCE_!*
====

This will generate some CPU intensive calculations.
(If you are curious about what it is doing you can click https://github.com/openshift-cs/ostoy/blob/master/microservice/app.js#L32[here]).

[NOTE]
====
The page may become slightly unresponsive.This is normal; so be patient while the new pods spin up.
====

==== See the pods scale up

After about a minute the new pods will show up on the page (represented by the colored rectangles).
Confirm that the pods did indeed scale up through the OpenShift Web Console or the CLI (you can use the command above).

[NOTE]
====
The page may still lag a bit which is normal.
====

==== Review metrics with observability

In the OpenShift web console left menu, click on _Observe > Dashboards_

In the dashboard, select _Kubernetes / Compute Resources / Namespace (Pods)_ and our namespace _ostoy_.

image::images/12-hpametrics.png[select_metrics]

Wait a few minutes and colorful graphs will appear showing resource usage across CPU and memory.
The top graph will show recent CPU consumption per pod and the lower graph will indicate memory usage.
Looking at this graph you can see how things developed.
As soon as the load started to increase (A), two new pods started to spin up (B, C).
The thickness of each graph is its CPU consumption indicating which pods handled more load.
We also see that the load decreased (D), after which, the pods were spun back down.

image::images/12-metrics.png[select_metrics]

=== Node Autoscaling

In ROSA one can also define https://docs.openshift.com/rosa/rosa_cluster_admin/rosa_nodes/rosa-nodes-about-autoscaling-nodes.html[node autoscaling].
You can also visit the link:/rosa/8-autoscaling[Node Autoscaling] section of this workshop for more information.

==== 1. Enable Autoscaling nodes on the machine pool

If you have not already enabled autoscaling on a machine pool the please see the link:/rosa/8-autoscaling/#setting-up-cluster-autoscaling[Setting up cluster autoscaling] section and follow the steps there to either enable autoscaling on an existing machine pool or create a new one with autoscaling enabled.

==== 2. Test the Cluster Autoscaler

* Create a new project where we will define a job with a load that this cluster cannot handle.
This should force the cluster to automatically create new nodes to handle the load.
+
Create a new project called "autoscale-ex":
+
----
  oc new-project autoscale-ex
----

* Create the job
+
----
  oc create -f https://raw.githubusercontent.com/openshift-cs/rosaworkshop/master/rosa-workshop/ostoy/yaml/job-work-queue.yaml
----

* After a few seconds, run the following to see what pods have been created.
+
----
  $ oc get pods
  NAME                     READY   STATUS    RESTARTS   AGE
  work-queue-5x2nq-24xxn   0/1     Pending   0          10s
  work-queue-5x2nq-57zpt   0/1     Pending   0          10s
  work-queue-5x2nq-58bvs   0/1     Pending   0          10s
  work-queue-5x2nq-6c5tl   1/1     Running   0          10s
  work-queue-5x2nq-7b84p   0/1     Pending   0          10s
  work-queue-5x2nq-7hktm   0/1     Pending   0          10s
  work-queue-5x2nq-7md52   0/1     Pending   0          10s
  work-queue-5x2nq-7qgmp   0/1     Pending   0          10s
  work-queue-5x2nq-8279r   0/1     Pending   0          10s
  work-queue-5x2nq-8rkj2   0/1     Pending   0          10s
  work-queue-5x2nq-96cdl   0/1     Pending   0          10s
  work-queue-5x2nq-96tfr   0/1     Pending   0          10s
----

* We see a lot of pods in a pending state.
This should trigger the autoscaler to create more nodes in our machine pool.
* After a few minutes let's check how many worker nodes we have.
+
----
  $ oc get nodes
  NAME                                         STATUS   ROLES          AGE     VERSION
  ip-10-0-138-106.us-west-2.compute.internal   Ready    infra,worker   22h     v1.23.5+3afdacb
  ip-10-0-153-68.us-west-2.compute.internal    Ready    worker         2m12s   v1.23.5+3afdacb
  ip-10-0-165-183.us-west-2.compute.internal   Ready    worker         2m8s    v1.23.5+3afdacb
  ip-10-0-176-123.us-west-2.compute.internal   Ready    infra,worker   22h     v1.23.5+3afdacb
  ip-10-0-195-210.us-west-2.compute.internal   Ready    master         23h     v1.23.5+3afdacb
  ip-10-0-196-84.us-west-2.compute.internal    Ready    master         23h     v1.23.5+3afdacb
  ip-10-0-203-104.us-west-2.compute.internal   Ready    worker         2m6s    v1.23.5+3afdacb
  ip-10-0-217-202.us-west-2.compute.internal   Ready    master         23h     v1.23.5+3afdacb
  ip-10-0-225-141.us-west-2.compute.internal   Ready    worker         23h     v1.23.5+3afdacb
  ip-10-0-231-245.us-west-2.compute.internal   Ready    worker         2m11s   v1.23.5+3afdacb
  ip-10-0-245-27.us-west-2.compute.internal    Ready    worker         2m8s    v1.23.5+3afdacb
  ip-10-0-245-7.us-west-2.compute.internal     Ready    worker         23h     v1.23.5+3afdacb
----

* We can see that more worker nodes were automatically created to handle the workload.
* Switch back to the "OSToy" project for the rest of the workshop.
+
----
  oc project ostoy
----
